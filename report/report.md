第一页：封面
老师们好，我是毛天宇，选择的项目是基于 diffVG（可微分渲染） 的 SVG 图像编辑，主要是颜色和拓扑结构两方面的编辑，我的代码和实验数据全部在 GitHub 开源。

---

第二页：项目目标
首先简单提一下项目目标，就是希望生成足够多数量与高质量的 SVG 图像对，为编辑 SVG 图像的大模型提供高质量的训练数据。

简单来说，我们输入一个原始 svg 图像以及参考 png 图像，经过我们的程序之后，能输出编辑后的 svg 图像。

我们主要完成两个任务：
- 一是保持 svg 图像的拓扑结构不变，完成颜色的迁移，这是基础任务。
- 二是实现物体的增删、修改，这是进阶任务。

我们的核心技术是基于 **DiffVG (Differentiable Vector Graphics)** 的可微分渲染。它允许我们将“渲染出的图片与参考图的像素误差 (Loss)”反向传播，从而计算出应该如何修改 SVG 的参数（控制点、颜色等）。这是一种基于**优化 (Optimization-based)** 的生成方法。

---

第三页：蒙版遮挡问题
我先来介绍基础任务中遇到的两个问题，以及我们对应的解决办法。

第一个问题是蒙版遮挡问题。就是，在我一开始得到的颜色编辑图像时，我发现所有图像上都存在一层颜色遮蔽，只能隐约看出轮廓。这个问题是由于路径 Alpha 锁死为 1.0 导致的

**Alpha** 就是透明度通道（0是全透，1是不透）。  
解决方法是：我们放弃了硬编码，借鉴了 **深度学习中“参数自适应”的思想**，开发了 **Smart Alpha 策略**。我们将透明度 (Alpha) 也设为**可学习的参数**，交给优化器。算法会自动发现：“哦，这层挡住了目标，Loss 很大”，从而自动把它变透明。右图展示了修复后的完美效果。

这样，通过动态调整 Alpha 的值，就成功解决了蒙版问题。

---

第四页：线条消失问题
第二个问题是线条消失问题，即优化过程中图像残缺，只生成了一部分，或者干脆生成了一些完全混乱的内容。

经过分析，有两个原因：
- 原始 SVG 包含了大量 **相对坐标 (m命令)** 和 **复合路径**。DiffVG 的解析器对这些复杂语法的支持有限，导致坐标计算漂移，数据读入时就丢了。
- 还有个原因是，细线条如果不小心和目标错位，优化器发现“删掉它”比“移动它”能更快降低误差，导致梯度消失。

解决方法是“**清洗+加粗**”：
- 我们通过清洗 svg 图像的内容（当然，图像本身在视觉上没有任何变化），将相对坐标改为绝对坐标，并将复合路径打散，让优化器更容易识别其内容；然后，通过增加线条宽度以及锁住形状的方式，让优化器保留并上色这些线条，而不是删掉它们。

最终得到了完美的效果。

----

第五页：基础任务展示
这是我们基础任务的生成结果。可以看到，生成结果和参考图还是十分接近的。

不过，这里也存在一个 tradeoff，我始终无法解决：就是解决蒙版问题之后，存在“描边线条”的图像，其“描边线条”都丢失了。也就是如 case1 和 case5 这样。（这个问题，我不太清楚原因是什么……我该怎么说呢？）

不过这里存在一个有趣的 Tradeoff：在 Case 1 和 5 中，大家可能会发现外轮廓的描边变淡了。这是因为我们在使用 **MSE 像素损失**。对于优化器来说，**填充颜色 (Fill)** 占据了 95% 的面积，贡献了主要的 Loss；而 **描边 (Stroke)** 占比很小。为了追求整体颜色的极致准确，优化器有时候会选择牺牲边缘的锐度来换取整体色块的融合。这也是未来可以引入 **LPIPS 感知损失** 来改进的地方。（这是对的吗？）


----

第六页：进阶任务中“误杀”的分析
然后简单介绍下进阶任务内容，我只做了一部分，就是删除原本 svg 图像中的内容。

我遇到的问题是，删除时容易误杀其他内容。

目前，对于较为简单的图片，我通过对比原图和参考图，综合评估各条路径的分数，删掉匹配度不足的内容，就能实现删除。

具体来说，我们的评分有这样四项指标
1.  **颜色匹配度：** 采样路径区域的颜色，看它在目标图中是否存在。
2.  **几何紧凑度：** 计算 $\frac{面积}{周长}$，圆形的眼睛得分高，杂乱的噪点得分低，从而保护眼睛。
3.  **面积权重：** 大块的身体绝对不删。
4.  **LOO 损耗评估 (Leave-One-Out)：** 试探性地关掉这个路径，如果 Loss 变小了，说明它是多余的，那就删掉。


可以看到，本来存在误杀鱼眼或者鱼边框线条的情况，后面就不存在这样的情况了，能精准删除鱼嘴。

-----

第七页：“拓扑破碎”问题分析
在做 **物体增加 (Spawning)** 时，我们观察到了有趣的 **“马赛克效应”**（左图眼镜部分）。新生成的物体是由很多细碎色块拼成的。

这是因为目前的生长算法采用了 **“迭代贪婪策略”**。它就像是在打补丁：哪里误差大，就在哪里生成一个小圆去填补。它缺乏全局的几何先验，不知道“眼镜”应该是一个完整的环。这揭示了纯微分渲染方法的局限性。

----

第八页：总结
简单总结一下，我们项目基本实现了 svg 图像自动化修改的流水线，能为下游模型训练提供较高质量的数据集。

未来，我们考虑引入其他方法，进一步解决拓扑破碎问题，例如语义分割模型
- SAM 模型就像是给优化器配了一副“眼镜”，它能直接识别出“这是一个完整的眼镜”或者“这是一只完整的手”，并生成对应的 Mask。有了这个先验形状作为初始状态，优化器就不需要用碎块去拼凑了，从而生成光滑、完整的几何结构。

以上就是汇报的全部内容，谢谢大家！